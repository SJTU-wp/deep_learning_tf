{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc_7Yr0N8znU",
        "outputId": "c122388d-0cfc-4c85-a533-892ed0d4ea83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "sys.version_info(major=3, minor=7, micro=13, releaselevel='final', serial=0)\n",
            "matplotlib 3.2.2\n",
            "numpy 1.21.6\n",
            "pandas 1.3.5\n",
            "sklearn 1.0.2\n",
            "tensorflow 2.8.0\n",
            "keras.api._v2.keras 2.8.0\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhE1Q-Et86Bl",
        "outputId": "5e4822d3-2bbb-4fb6-b0b0-956d609c2477"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May 23 03:28:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nxejbzgv8znX"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6nBNKV88znX",
        "outputId": "ef0a235e-db4e-4c6c-a713-594c895453aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am a man!. ? \n",
            "imasn\n"
          ]
        }
      ],
      "source": [
        "# 这里正则表达式中的^：一直吃直到......（可以理解为“取反”）\n",
        "b = \"I am a[]=+ man!. ? &***()\"\n",
        "b = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", b)\n",
        "print(b)\n",
        "c = '12345 im asn'\n",
        "c = re.sub(r\"[^a-z]+\", \"\", c)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLGLZD1D8znY",
        "outputId": "3e3d7f28-83b5-4761-d2ac-f11ffdbe6329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "May I borrow this book?\n",
            "¿Puedo tomar prestado este libro?\n",
            "<start> may i borrow this book ? <end>\n",
            "<start> ¿ puedo tomar prestado este libro ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ]
        }
      ],
      "source": [
        "# 因为西班牙语有一些是特殊字符，所以需要unicode转ascii\n",
        "# 这样值变小了，因为unicode太大\n",
        "def unicode_to_ascii(s):\n",
        "    # NFD是转换方法，把每一个字节拆开，Mn是重音，所以去除\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "# 简单测试\n",
        "# 加u代表对字符串进行unicode编码\n",
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "\n",
        "print(unicode_to_ascii(en_sentence))\n",
        "print(unicode_to_ascii(sp_sentence))\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    # 变为小写，去掉多余的空格\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # 在单词与跟在其后的标点符号之间插入一个空格\n",
        "    # eg: \"he is a boy.\" => \"he is a boy . \"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    # 因为可能有多余空格，替换为一个空格，所以处理一下\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # 除了 (a-z, A-Z, \".\", \"?\", \"!\", \",\")，将所有字符替换为空格（上一个cell中有演示）\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))  # ¿是占用两个字节的"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWJsS8vc8znZ",
        "outputId": "0f39752d-bb54-432e-ac0a-9dd0989cdf72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tuple'>\n",
            "<class 'tuple'>\n",
            "118964\n",
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ]
        }
      ],
      "source": [
        "data_path = './spa.txt'\n",
        "\n",
        "# 1. Remove the accents  移除口音\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]--> 前面西班牙，后面英文\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    # word_pairs是二维列表\n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "    \n",
        "    return zip(*word_pairs)\n",
        "\n",
        "en, sp = create_dataset(data_path, None)\n",
        "print(type(en))\n",
        "print(type(sp))\n",
        "print(len(en))\n",
        "print(en[-1])\n",
        "print(sp[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeRCqItd8zna",
        "outputId": "c506ff74-ce32-4029-c840-d335e869afc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 3, 5) (2, 4, 6)\n"
          ]
        }
      ],
      "source": [
        "# zip演示\n",
        "a=[ [1, 2],[3,4],[5,6] ]\n",
        "c,d=zip(*a)  # *：解包\n",
        "print(c,d)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAkiqnok8zna",
        "outputId": "7ee1c62d-1423-47e7-9d7f-b8cc6ca8e047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "(30000, 16) (30000, 11) <keras_preprocessing.text.Tokenizer object at 0x7f63ee8ec0d0> <keras_preprocessing.text.Tokenizer object at 0x7f63ececba50>\n",
            "--------------------------------------------------\n",
            "[  1 135   3   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "[ 1 36  3  2  0  0  0  0  0  0  0]\n",
            "[   1   23 2175   10   39   98   87  314    3    2    0    0    0    0\n",
            "    0    0]\n",
            "[ 1 16 38 72  6 55  3  2  0  0  0]\n",
            "11 16\n"
          ]
        }
      ],
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "def tokenize(lang):\n",
        "    # Tokenizer帮我们把词语式的转换为id式的，filters是黑名单\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    # 把一个一个的单词变为id\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    # 做padding，向最大的补齐\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "    return tensor, lang_tokenizer\n",
        "\n",
        "def load_dataset(path, num_examples=None):\n",
        "    # creating cleaned input, output pairs，目前是西班牙语翻译为英语\n",
        "    targ_lang, inp_lang = create_dataset(path, num_examples)  # 如果要翻译互换，只需交换这里\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
        "\n",
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "# inp_lang  targ_lang 是tokenizer\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(data_path, num_examples)\n",
        "print('-'*50)\n",
        "print(input_tensor.shape, target_tensor.shape, inp_lang, targ_lang)\n",
        "print('-'*50)\n",
        "print(input_tensor[0])\n",
        "print(target_tensor[0])\n",
        "print(input_tensor[29999])\n",
        "print(target_tensor[29999])\n",
        "# Calculate max_length of the target tensors，可以看下最长的样本\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "print(max_length_targ, max_length_inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeef_qYX8znb",
        "outputId": "5b469c78-da48-45e5-d2a8-58c2dd73b0b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24000, 24000, 6000, 6000)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4d8t-vM8znb",
        "outputId": "66236add-fc2c-43c1-c140-74856d87ad80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "62 ----> estan\n",
            "3124 ----> peleando\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "28 ----> they\n",
            "23 ----> re\n",
            "863 ----> fighting\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ]
        }
      ],
      "source": [
        "# 按单词进行切分的\n",
        "def convert(lang, tensor):\n",
        "    for t in tensor:\n",
        "        # 不等于0，就打印转换\n",
        "        if t != 0:\n",
        "            print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
        "            \n",
        "print(\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print()\n",
        "print(\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])\n",
        "# 可以发现tokenizer正常工作"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q50PThd8znc",
        "outputId": "7b2ee366-d108-4643-b76c-8013fdebc4bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9414\n",
            "4935\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(64, 16), dtype=tf.int32, name=None), TensorSpec(shape=(64, 11), dtype=tf.int32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "# 分batch\n",
        "BUFFER_SIZE = len(input_tensor_train)  # 就是3万\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "# 下面两个都是超参数\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "# 输入的,加1考虑到padding的0\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "print(vocab_inp_size)\n",
        "# 输出,加1考虑到padding的0\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "print(vocab_tar_size)\n",
        "# 训练集\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)  # 最后一个batch丢弃\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7Mh4wSm8znc",
        "outputId": "55ed5e54-af10-4e6d-ff5f-8be50197d34f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# 测试，看一下迭代\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcJMpJEJ8znc",
        "outputId": "17ce36ac-d6a1-4a7b-9971-3fca55dbb871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ],
      "source": [
        "# 手法和之前的类似\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, encoding_units, batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        # 编码单元\n",
        "        self.encoding_units = encoding_units\n",
        "        # 创建Embedding层\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        # 定义GRU层，gru是lstm变种，gru把遗忘门和输入门变为一个，因为遗忘门+输入门=1\n",
        "        # return_state返回最后一个细胞的中间状态\n",
        "        self.gru = keras.layers.GRU(self.encoding_units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output,state= self.gru(x, initial_state = hidden)\n",
        "        return output,state\n",
        "\n",
        "    def initialize_hidden_state(self):  # 初始化全零的隐含状态\n",
        "        return tf.zeros((self.batch_size, self.encoding_units))\n",
        "    \n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "# 获得初始化的hidden\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "# 获得输出和隐含状态\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "# 输出的16是长度，1024是状态的size,是因为return_sequences为True，每一个输出都需要\n",
        "print('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL3Cy17x8znd",
        "outputId": "3e85e0ad-2b69-497c-fb94-3495fe660ba5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'encoder/embedding/embeddings:0' shape=(9414, 256) dtype=float32, numpy=\n",
              " array([[ 0.00508187,  0.00677835, -0.00812074, ...,  0.0224557 ,\n",
              "          0.03751332, -0.0232367 ],\n",
              "        [-0.01384448,  0.02161532,  0.02728904, ..., -0.03109216,\n",
              "         -0.03132951, -0.03317243],\n",
              "        [ 0.03537544, -0.01183152,  0.0463004 , ...,  0.03646449,\n",
              "          0.02015119,  0.04910404],\n",
              "        ...,\n",
              "        [ 0.00805224, -0.03630978,  0.03525568, ...,  0.03063103,\n",
              "          0.04689275, -0.02259804],\n",
              "        [ 0.02862669,  0.04981694,  0.03529224, ..., -0.02729468,\n",
              "          0.02312548, -0.0399763 ],\n",
              "        [ 0.04396899, -0.03623163, -0.03728576, ..., -0.03768947,\n",
              "          0.0412076 , -0.02624229]], dtype=float32)>,\n",
              " <tf.Variable 'encoder/gru/gru_cell/kernel:0' shape=(256, 3072) dtype=float32, numpy=\n",
              " array([[-0.01588795,  0.02624664, -0.01251672, ...,  0.04093488,\n",
              "         -0.04146188,  0.00690464],\n",
              "        [-0.02303928,  0.03387072, -0.03228163, ..., -0.0070832 ,\n",
              "         -0.03896256, -0.03859939],\n",
              "        [-0.02693223, -0.03776484, -0.00410618, ..., -0.01749533,\n",
              "         -0.03766923, -0.01601061],\n",
              "        ...,\n",
              "        [-0.02974124, -0.01232943,  0.01682984, ...,  0.03459376,\n",
              "         -0.01595738, -0.01968549],\n",
              "        [ 0.03621357,  0.02630799, -0.01836326, ..., -0.00143525,\n",
              "         -0.00827715,  0.02570003],\n",
              "        [-0.03048539,  0.02442031, -0.03945583, ..., -0.01191305,\n",
              "         -0.02168871, -0.00857301]], dtype=float32)>,\n",
              " <tf.Variable 'encoder/gru/gru_cell/recurrent_kernel:0' shape=(1024, 3072) dtype=float32, numpy=\n",
              " array([[-0.02650999, -0.01754935,  0.00352689, ...,  0.03597448,\n",
              "         -0.01697975,  0.0208484 ],\n",
              "        [ 0.01091985, -0.02156423, -0.00645085, ..., -0.03302739,\n",
              "         -0.0099162 , -0.01918872],\n",
              "        [-0.02323581, -0.01618671,  0.01365787, ..., -0.00154017,\n",
              "          0.01015556, -0.0365909 ],\n",
              "        ...,\n",
              "        [-0.01193818, -0.00074509, -0.02440635, ..., -0.02173104,\n",
              "         -0.00835711,  0.00551866],\n",
              "        [ 0.01700506, -0.03761088, -0.03603493, ...,  0.005722  ,\n",
              "         -0.01874246,  0.02017398],\n",
              "        [ 0.02360175, -0.00063751, -0.00559203, ..., -0.03367723,\n",
              "         -0.03426366, -0.00654384]], dtype=float32)>,\n",
              " <tf.Variable 'encoder/gru/gru_cell/bias:0' shape=(2, 3072) dtype=float32, numpy=\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# 理解模型中去做的运算\n",
        "encoder.variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHUA5EwY8znd"
      },
      "source": [
        "# 核心部分"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRoyT-6I8zne",
        "outputId": "2b2a55c9-da42-48c0-e82b-52e9a0b2b88a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 16, 1024)\n",
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ]
        }
      ],
      "source": [
        "# 实现Attention机制\n",
        "class BahdanauAttention(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        # 做全连接\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "    \n",
        "    # query传的是decoder_hidden,values是EO\n",
        "    def call(self, query, values):\n",
        "        # deocoder_hidden.shape: (batch_size,units)\n",
        "        # encoder outputs.shape: (batch size, length,units)\n",
        "        # 做维度扩展，扩展前后对比是下面两行\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "        \n",
        "        #接下来要实现Attention,Bahdanau方式的\n",
        "        # before V:(batch_size, length, units )\n",
        "        # after V: (batch_size, length, 1)\n",
        "        # score shape == (batch_size, max_length, 1)  （64,16,1）\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        # 先算加权，values就是encoder_outputs，对应位置相乘，广播出去\n",
        "        # context_vector.shape: ( batch_size, length units )\n",
        "        context_vector = attention_weights * values\n",
        "        print(context_vector.shape)\n",
        "        # 在length的维度去求和\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "    \n",
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47GqHQpo8znf",
        "outputId": "769fc7d5-f857-4713-e70c-a5407199a8c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'bahdanau_attention/dense/kernel:0' shape=(1024, 10) dtype=float32, numpy=\n",
              " array([[ 0.06464614, -0.00774927,  0.00676966, ...,  0.03257685,\n",
              "         -0.07436984,  0.0649657 ],\n",
              "        [-0.06563891, -0.06577568,  0.05749071, ...,  0.0029221 ,\n",
              "          0.03592245,  0.00611632],\n",
              "        [ 0.00048519, -0.05783436, -0.03657306, ..., -0.07314355,\n",
              "         -0.00906719,  0.05881111],\n",
              "        ...,\n",
              "        [-0.00706928, -0.03874933,  0.02018823, ..., -0.02200363,\n",
              "          0.07418783, -0.06143684],\n",
              "        [ 0.04965284,  0.03402801,  0.022896  , ..., -0.05754478,\n",
              "          0.0737655 , -0.00838722],\n",
              "        [-0.05296246, -0.05527399, -0.02907558, ...,  0.035278  ,\n",
              "          0.03000916, -0.06230796]], dtype=float32)>,\n",
              " <tf.Variable 'bahdanau_attention/dense/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'bahdanau_attention/dense_1/kernel:0' shape=(1024, 10) dtype=float32, numpy=\n",
              " array([[-0.0492903 ,  0.02040844, -0.05555546, ...,  0.00050201,\n",
              "         -0.03122623, -0.07477368],\n",
              "        [-0.06794289, -0.06234895,  0.02140916, ..., -0.03221077,\n",
              "         -0.07282186, -0.02419986],\n",
              "        [ 0.04266237, -0.01882095,  0.0750861 , ...,  0.07420757,\n",
              "         -0.06795872, -0.04861369],\n",
              "        ...,\n",
              "        [-0.04012266, -0.02241481,  0.05310872, ..., -0.01023023,\n",
              "          0.05847511,  0.01346589],\n",
              "        [ 0.06112333,  0.04843859,  0.01131108, ...,  0.03043982,\n",
              "          0.04394062,  0.06282021],\n",
              "        [ 0.01768096,  0.02266943, -0.06493426, ..., -0.02288102,\n",
              "         -0.02983167,  0.02018038]], dtype=float32)>,\n",
              " <tf.Variable 'bahdanau_attention/dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'bahdanau_attention/dense_2/kernel:0' shape=(10, 1) dtype=float32, numpy=\n",
              " array([[ 0.5716627 ],\n",
              "        [ 0.16512501],\n",
              "        [ 0.03870636],\n",
              "        [-0.326515  ],\n",
              "        [ 0.6982669 ],\n",
              "        [ 0.616569  ],\n",
              "        [ 0.04383463],\n",
              "        [-0.5625662 ],\n",
              "        [ 0.65367883],\n",
              "        [ 0.22410023]], dtype=float32)>,\n",
              " <tf.Variable 'bahdanau_attention/dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "attention_layer.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljoD4exi8znf",
        "outputId": "8ca9d2b6-99fa-414e-bd4e-f32858f921d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n",
            "decoder_hidden.shape:  (64, 1024)\n",
            "decoder_attention_weights.shape: (64, 16, 1)\n"
          ]
        }
      ],
      "source": [
        "# 实现decoder\n",
        "class Decoder(tf.keras.Model):\n",
        "    # init传参和encoder很像\n",
        "    def __init__(self, vocab_size, embedding_dim, decoding_units, batch_size):\n",
        "        # 这里必须调用父类\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.decoding_units = decoding_units\n",
        "        # Embedding 层\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        # GRU的decoder\n",
        "        self.gru = keras.layers.GRU(self.decoding_units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "        self.fc = keras.layers.Dense(vocab_size)\n",
        "\n",
        "        # used for attention，每一步都会被调用\n",
        "        self.attention = BahdanauAttention(self.decoding_units)\n",
        "\n",
        "    # 照着原来的原理图理解\n",
        "    def call(self, x, hidden, encoding_output):\n",
        "        # context vector. shape: ( batch size, units）\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden, encoding_output)\n",
        "\n",
        "        # before embedding: x. shape: (batch_size, 1 )\n",
        "        # after embedding : x. shape: (batch size, 1, embedding units)\n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        print(context_vector.shape,x.shape)\n",
        "        # 把x和context_vector拼起来，context_vector为什么要扩展维度？\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        print(x.shape)\n",
        "        # passing the concatenated vector to the GRU\n",
        "        # output. shape:[batch_size,1,decoding_units ]\n",
        "        #state. shape:[batch_size, decoding_units ]\n",
        "        output, state = self.gru(x)\n",
        "        print(output.shape)\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        print('output变换后')\n",
        "        print(output.shape)\n",
        "        # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "sample_decoder_output,decoder_hidden,decoder_aw = decoder(tf.random.uniform((64, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n",
        "print(\"decoder_hidden.shape: \", decoder_hidden.shape )\n",
        "print(\"decoder_attention_weights.shape:\", decoder_aw.shape )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dfzaysFq8znf"
      },
      "outputs": [],
      "source": [
        "# 优化器选用adam\n",
        "optimizer = keras.optimizers.Adam()\n",
        "# 分类问题我们往往用SparseCategoricalCrossentropy，因为我们的fc是纯的输出，没有加softmax，\n",
        "# 因此这里的from_logits为True，否则改为false，reduction是损失函数如何做聚合\n",
        "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "# 为了把padding部分的损失去除，这样计算损失更加准确\n",
        "def loss_function(real, pred):\n",
        "    # 是零的时候返回结果是True，因此要取反操作\n",
        "    # tf.math.equal(real, 0)是padding的部分都是1，不是padding的部分都是零，因此我们要取反\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    \n",
        "    loss_ = loss_object(real, pred)  # 这里是得到的损失\n",
        "    # 将张量转换为新类型,变为float类型\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    # padding部分的mask是零\n",
        "    loss_ *= mask\n",
        "    # 计算累计的损失平均\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "checkpoint_dir = './8-1_checkpoints'\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.mkdir(checkpoint_dir)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgkVT0Sv8zng",
        "outputId": "8b841345-9be6-4f7b-f394-f54d74cda349"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 1), dtype=int32, numpy=\n",
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "X3AdyeWn8zng"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, encoding_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # 把输入给encoder，得到encoding_output, encoding_hidden\n",
        "        encoding_output, encoding_hidden = encoder(inp, encoding_hidden)\n",
        "\n",
        "        decoding_hidden = encoding_hidden  # 最初是把encoding_hidden给decoding\n",
        "        # 第一次给进去的decoding_input全部是1，是64个1\n",
        "        decoding_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "        \n",
        "        # eg: <start> I am here <end>\n",
        "        # 1.<start>->I\n",
        "        # 2.I->am\n",
        "        # 3.am->here\n",
        "        # 4. here ->< end>\n",
        "        # 对于here，我们相当于要把I am  的信息都要给过去\n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # passing enc_output to the decoder\n",
        "            # 根据我们前面的原理解析，我们这里需要给3项信息\n",
        "            predictions, decoding_hidden, _ = decoder(decoding_input, decoding_hidden, encoding_output)\n",
        "\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "            # using teacher forcing,这里是取第t列，再扩维\n",
        "            decoding_input = tf.expand_dims(targ[:, t], 1)\n",
        "            \n",
        "    # 这里是每个batch上平均的损失函数\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    print(type(encoder.trainable_variables))\n",
        "    print(type(decoder.trainable_variables))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    # 求梯度\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    # 有了梯度以后，可以用optimizer去做apply\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp_1n7Hu8zng",
        "outputId": "4afdc697-dde1-46ed-b39c-ad9d5711da9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "m=np.arange(6).reshape(3,2)\n",
        "t=1\n",
        "m[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k3ZkUUY8zng",
        "outputId": "01f21744-afc0-4a8b-ef8c-033e8e24c6aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "steps_per_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoGX748F8zng",
        "outputId": "51745ca4-fa00-4902-eaf7-e29578488211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 1024) (64, 1, 256)\n",
            "(64, 1, 1280)\n",
            "(64, 1, 1024)\n",
            "output变换后\n",
            "(64, 1024)\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "Epoch 1 Batch 0 Loss 4.5418\n",
            "Epoch 1 Batch 100 Loss 2.0873\n",
            "Epoch 1 Batch 200 Loss 1.8962\n",
            "Epoch 1 Batch 300 Loss 1.6892\n",
            "Epoch 1 Loss 2.0147\n",
            "Time taken for 1 epoch 40.32993173599243 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.5840\n",
            "Epoch 2 Batch 100 Loss 1.4102\n",
            "Epoch 2 Batch 200 Loss 1.2619\n",
            "Epoch 2 Batch 300 Loss 1.2685\n",
            "Epoch 2 Loss 1.3648\n",
            "Time taken for 1 epoch 26.905471563339233 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0800\n",
            "Epoch 3 Batch 100 Loss 1.1088\n",
            "Epoch 3 Batch 200 Loss 0.9097\n",
            "Epoch 3 Batch 300 Loss 0.9125\n",
            "Epoch 3 Loss 0.9599\n",
            "Time taken for 1 epoch 26.56162691116333 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6752\n",
            "Epoch 4 Batch 100 Loss 0.7210\n",
            "Epoch 4 Batch 200 Loss 0.5932\n",
            "Epoch 4 Batch 300 Loss 0.6531\n",
            "Epoch 4 Loss 0.6414\n",
            "Time taken for 1 epoch 27.40373969078064 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4061\n",
            "Epoch 5 Batch 100 Loss 0.4278\n",
            "Epoch 5 Batch 200 Loss 0.4252\n",
            "Epoch 5 Batch 300 Loss 0.4955\n",
            "Epoch 5 Loss 0.4296\n",
            "Time taken for 1 epoch 27.119643926620483 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.3209\n",
            "Epoch 6 Batch 100 Loss 0.2425\n",
            "Epoch 6 Batch 200 Loss 0.2823\n",
            "Epoch 6 Batch 300 Loss 0.3094\n",
            "Epoch 6 Loss 0.2949\n",
            "Time taken for 1 epoch 27.879979610443115 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1702\n",
            "Epoch 7 Batch 100 Loss 0.2535\n",
            "Epoch 7 Batch 200 Loss 0.2478\n",
            "Epoch 7 Batch 300 Loss 0.2146\n",
            "Epoch 7 Loss 0.2081\n",
            "Time taken for 1 epoch 27.44938087463379 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1705\n",
            "Epoch 8 Batch 100 Loss 0.1542\n",
            "Epoch 8 Batch 200 Loss 0.1670\n",
            "Epoch 8 Batch 300 Loss 0.1776\n",
            "Epoch 8 Loss 0.1511\n",
            "Time taken for 1 epoch 28.190237760543823 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1352\n",
            "Epoch 9 Batch 100 Loss 0.1538\n",
            "Epoch 9 Batch 200 Loss 0.0824\n",
            "Epoch 9 Batch 300 Loss 0.1545\n",
            "Epoch 9 Loss 0.1182\n",
            "Time taken for 1 epoch 27.815499782562256 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0716\n",
            "Epoch 10 Batch 100 Loss 0.1127\n",
            "Epoch 10 Batch 200 Loss 0.1140\n",
            "Epoch 10 Batch 300 Loss 0.1169\n",
            "Epoch 10 Loss 0.0963\n",
            "Time taken for 1 epoch 28.456782817840576 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "# 这里运行时间比较久\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    encoding_hidden = encoder.initialize_hidden_state()  # 第一次，全零的隐含状态\n",
        "    total_loss = 0\n",
        "    # 每次去取dataset.take(steps_per_epoch)这么多数据\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, encoding_hidden)\n",
        "        total_loss += batch_loss\n",
        "        # 这里增加打印\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "    # saving (checkpoint) the model every 2 epochs，保存模型\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eayUCmKm8znh"
      },
      "source": [
        "# 预测过程（翻译）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HqTSjXw8znh",
        "outputId": "4d550bf1-3d47-4cd7-9e74-467ac0a536b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f63eb79e310>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# 接收字符串，并进行翻译\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    # 对输入的语言做和训练时同样的预处理（eg: 标点符号前后加空格）后，下一步再进行word转id\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    # text到id的转换\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    # 加padding\n",
        "    inputs = keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)  # 变为张量\n",
        "    # 结果先初始化一个空串\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    encoding_out, encoding_hidden = encoder(inputs, hidden)\n",
        "    # 按模型把encoding_hidden给decoding_hidden\n",
        "    decoding_hidden = encoding_hidden\n",
        "    # 第一次的decoding_input是全为1的（1,1)的矩阵\n",
        "    decoding_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "    # eg:<start>->A\n",
        "    # A->B->C->D\n",
        "    # decoding_input. shape:(1， 1)\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, decoding_hidden, attention_weights = decoder(\n",
        "            decoding_input, decoding_hidden, encoding_out)\n",
        "        \n",
        "        # attention weights. shape: (batch size, input length, 1) (1， 16， 1 )，需要变为长度为16的向量\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()  # 为了画图\n",
        "        # predictions.shape: (batch_ size, vocab_ size) (1, 4935)\n",
        "        # 获取概率最大的值作为下一步的输入\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        # 通过id知道单词\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "        \n",
        "        # 终止循环\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        decoding_input = tf.expand_dims([predicted_id], 0)\n",
        "    # 到此decoding_input，decoding_hidden我们都做了更新\n",
        "    \n",
        "    return result, sentence, attention_plot\n",
        "\n",
        "# function for plotting the attention weights，把注意力关系完成可视化\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "    # 把标注写上，我们需要把第零个位置空出来，看图即可看出\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# 通过这个函数，把上面两个函数串起来\n",
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    \n",
        "    # 因为输出不一定有输入的长度长，也就是result长度小于输入的长度\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
        "    \n",
        "# 加载模型参数\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XfPjuGV_8znh",
        "outputId": "be56ab27-f7bb-47c0-f55e-f9ff7bfe1c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAJwCAYAAAC08grWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZilB1Xv+99KOiQmMSCDEFEkMsgMQotMR1DUnAPO1wkDgpxLHOAKghNy1Mg5gCAOKE5BhcukIgcu0xFlFBQQAyIgY2SWIUQDJBBCSNb9490NVUV1BuzU2tX1+TxPP0/Vu3ftWvWm0/tb71jdHQCACUdMDwAA7F1CBAAYI0QAgDFCBAAYI0QAgDFCBAAYI0QAgDFCBAAYI0QAgDFCBAAYI0TWQFXdoKpeWlU3n54FAHaSEFkP905ylyT3HZ4DAHZUuendrKqqJO9J8qIk35HkK7r7otGhAGCH2CIy7y5JvjTJTyX5bJK7jU4DADtIiMy7d5Jndvenkvz56nMA2BPsmhlUVccl+VCSu3f3K6vqVkleneTE7v7Y7HQAcMWzRWTW/5Xk7O5+ZZJ09xuSvDPJD41OBcCuV1XHVdWPVNWVp2e5JEJk1r2SPHXLsqcmuc/OjwLAYeYHkjwxy3vN2rJrZkhVfVWSdye5cXe/c8Pyr8xyFs1NuvsdQ+OxBqrqFkl+JslNknSStyT59e5+8+hgwK5QVS9Lcs0kn+ru/dPzHIwQgTVUVd+Z5FlJXpnk71aL77T6873d/byp2YD1V1XXTfKOJLdN8pokt+7ut0zOdDBCZFBVXSfJ+3ub/whVdZ3uft/AWKyBqnpjkmd3969sWf7wJN/V3becmQzYDarql5LcpbvvWlXPSvLO7v756bm24xiRWe9Oco2tC6vqaqvH2LtumOQp2yx/SpKv3eFZgN3nR/L5f0OeluSU1QU0144QmVVZ9v1vdXyST+/wLKyXs5LcZpvlt0nykR2eBdhFquoOSU5M8szVouclOTbJt4wNdQn2TQ+wF1XV76w+7CSPqqpPbXj4yCz79N6w44OxTp6Q5I+q6vpJXrVadscsB6/++thUwG5w7yTP6e7zkqS7P1NVz8hyRuaLJgfbjmNEBqyOZE6SO2e5gNlnNjz8mSxnzTx249k07C2rTagPSvKQJF+xWvzBLBHyO9sdVwRQVUcn+XCSe3T3Czcsv1OSv05yzQOBsi6EyJDVG80zkty3u8+dnof1VVVfmiT+ngCXpqqunuWeZU/t7ou3PHbPJC/u7g+PDHcQQmRIVR2Z5TiQW67rKVUAcEVzjMiQ7r6oqt6b5ErTs7B+quqqSR6R5K5JvjxbDizv7hMm5gI41ITIrP+Z5Neq6p7dffb0MKyVP0nydUlOz3JsiE2XwEFV1btzGf+d6O6vuYLHuVzsmhlUVW9KclKSo5J8IMknNz7e3beYmIt5VfWJJN/a3f8wPQuw/qrqIRs+PT7Jg5O8NssJEUly+yxnZP5Gdz98h8e7RLaIzHrmpT+FPeqsJGt1ZDuwvrr7Nw58XFVPSvLo7n7kxudU1UOT3HSHR7tUtojAGqqqH8xy58x7r9updsB6W21RvXV3n7ll+fWTvH7djjGzRYS1UVU/meT+WXZX3ay731VVv5DkXd39jNnprnirXXUbfzM4KclZq4OaL9z4XLvtgEvwySR3SXLmluV3SfKprU+eJkQGVdWVkjwsyT2SXCfLsSKf091HTsw1oaoelOTnkjw6ya9teOjfkjwgyzVXDnd21QGHwm8l+b2q2p/lzrtJcrssV1w9bWqog7FrZlBVPTrJDyZ5VJa/OP8jyXWT/FCSX+ruP5qbbmdV1duSPKS7X1BV52a5vsq7quqmSV7R3VcbHhFGVdWtk7yhuy9efXxQ3f36HRqLNVVVP5DkgUluvFr01iSPW8ety0Jk0Op0q5/o7heu3nxv1d3/WlU/keSu3f19wyPumKo6P8mNuvu9W0Lkhln+8T12eMQdVVV3TpLu/tttlnd3v2JkMMZU1cVJrtXdZ60+7iw3ztyq99LWVHY/u2ZmXTPJgauqnpfkKquPX5hlF8Ve8q4kt07y3i3L75bPr6O95LeSbHeK3QlZNq1ud2deDm8nJfnoho/hUlXVVfKFF0T8j6FxtiVEZr0vyw3N3pfloKKTk7wuy/ne5w/ONeGxSR5fVcdm+S3v9lV1ryzHjdx3dLIZX5vkn7dZ/ubVY+wx3f3e7T6Grarqq5P8YZaDUzdevbuybElbqy1mQmTWs7Ncwvs1SR6X5M+q6n5Jrp09dqv37n5iVe1L8sgkxyZ5SpYriv5Ud//F6HAzzk9yYpJ3b1l+7Wy+WzN7kGNEuBRPzLKF/b9nF1yZ2TEia6SqviHJHZO8o7ufPz3PlNXdI4/o7rOmZ5lSVU/LcibVd3b3OatlV03ynCQf6O57TM7HrIMcI/K5f8wdI7K3VdV5SW7X3W+enuWyECKDquobk7yquz+7Zfm+JHfYSwckrs6OObK737hl+S2SfHav3aG4qk5M8oosN7w7sE5ukeWKq3fu7g9Ozca81ab3jY7Kcm+ihyV5aHf/1c5PxbpYXZPoPt39uulZLgshMqiqLkpy4tbf/KvqaknO2ku/1VTV3yf5ve5++pblP5TkAd19p5nJ5qyOlzklya1Wi/4pydO7e+0uSLQTquqbk9wky2/+b+nulw2PtHaq6tuS/Ep333F6Fuas/l/5hSQ/ufXqqutIiAxabV69Znd/dMvyGyY5Y90uw3tFWp2y+3XbXJL4elkuSXzlmcmYVlXXznI81W2y7O9OloO8z0jyPbYOfV5V3SDL6e7HTc/CnNW/p0dnOSj1giSbtrqv23uLg1UHVNVzVx92kqdW1QUbHj4yyc2SvGrHB5t1UZLtYuPLsv21Eg5rVfW9l/R4dz9rp2ZZA7+T5e/H9bv73UlSVV+T5Kmrx/bM9XYOWB0vtGlRloObT0vy9h0fiHXzgOkBLg9bRAZU1RNXH947y6XLN56q+5kk70nyhO4+e4dHG1NVz8nyZvP93X3Ratm+JH+Z5Kju/vbJ+XbaamvZdjrZWwcjrm7gdZetZ4KsLl/9kr24tWzDwaqbFid5f5If7O7XfOFXwXqyRWRAd/9oklTVe5I8trs/OTvRWvi5JH+X5Myq+rvVsjslOT7JN45NNaS7N12AaBVlX5fltO6HjQw1a7vfmPbyb1HftOXzi7Nc7OzMrQe/szdV1TWT3CvJ9bLcMuTsqrpjkg8e2LK4LmwRGVRVRyRJd1+8+vxaSb49y4F4e23XzIEzRR6QzQdn/r5jAD6vqu6Q5A+6+5bTs+yUqnp2kmskuUd3v3+17DpJnpbko919ibuxYK+pqtskeUmW6xDdNMvtM95VVacluWF3//DkfFsJkUFV9VdJXtjdj6uq45O8LclxWbYC/PfufvLogKydqrpJktd29/HTs+yUqvqqJM/NcuzUxoNV35TlOisfmJptyurU/8tkL10GgEVVvSzLzUJ/Zcu9u26f5M+7e+vp36Psmpm1P8suiST53iSfyHIPiVOS/EySPRciVfUVWS7ktfGyxHvuH9Ntrpx54GDEn8+ypWjP6O73r9bHtyS50WrxW7v7xYNjTXt5Pr9r6sDB3Fs/P7BszxxPxOfcJstVVbf6UJZ7nK0VITLr+CQfW338bUme3d0XVtVLk/ze3Fg7bxUgT89yPMiBK0Zu3Fy31/4xPSPb3131NdmD997pZdPti1Z/WHbhPjbJI5K8erXs9kl+McsvNw5W3dvOz3LG4VY3ynJRxLUiRGa9L8kdq+p5WW549/2r5VdNstcuWvXbWc6auUmSf0zyX7OU+8OT/PTgXFO23l314izHQ3x6YpidVlUPznJ80KdXHx9Ud//mDo21Tv5nkgd298Ywe1dVnZXkMd39dUNzsR6ek+RXqurAe0pX1XWz3NX9f08NdTCOERlUVT+W5PFJzkvy3iS37u6Lq+qnknx3d3/z6IA7qKo+kuTu3X3G6nTN/d39jqq6e5Yjvm83POKOWx31fscsl3nfehvv3x8ZaodU1buz/B3499XHB9Pd/TU7Nde6qKrzs/x78dYty2+S5HXd/SUzk7EOquqEJP8ny20hjkvy4Sy/2L0qyX9btzM1hciw1dHN10nyou4+b7Xs7kk+1t1/PzrcDlrFxy26+z2r05rv2d1/V1UnJfmX7j52dsKdVVX3TPLHWXbNnJPNu6m6u79iZDDWQlWdkeTMJD/a3eevln1JlruuXr+790/Ox3pYXer91ll+kXn9uh5XZdfMkKq6cpY33lcm2Xpjoo8l2VM3ectyxtCNslzM7Q1Jfryq3p/k/kn+bXCuKY9I8pgkD9/L14WoqqOyXF/mR7rbFUM/7yeSPD/Jv1XVgZsi3jzL7s27j03FuI3vLd390iQv3fDYHbNcHuKcsQG3YYvIkKr60ixHMJ+8cctHVd0yyWuTXHuPXVn1lCxXUH3S6gyJFya5epb7JNy7u58xOuAOq6pzktymu981Pcu01XEPd+rud0zPsk6q6rgkP5zkxqtFb81yU8S12uzOztqN7y1CZFBVPS3Jed39YxuWPTbLBWe+c26yeas7z94oyfvW7X+anVBVj0/y9u7+3elZplXVrydJd//s9CzrZHW13dtm+9Pd99yp/3zebntvESKDqurkJH+W5Frd/ZnVlVY/kOW293vppmZJkqr6wSR3zfYHZ67d/zxXpKq6UpL/L8u9h96U5MKNj3f3wyfmmlBVv5/l2jrvzrIbc9Nv/N39UxNzTaqqGyV5XpazqyrLLpl9Wf6eXLBud1dlZ+229xbHiMx6UZbzvb89ybOyvAlfKcs/MHvK6rfeByV5WZarZ+71Qv6xLKcwn53k+tlysGqW05oPW6srh75qdXzMjZMcuOHd1jNk9urfk9/OEmW3ynJGxK2y3L36D5L8j8G5WA+76r3FFpFhVfXoJF/b3d9dVU9Ocm533396rp22On33/t39zOlZ1sHquIhHdfdvTc8yoaouSnJid59VVe9K8vXd/e/Tc62Lqvr3JHfu7jdX1ceT3La7315Vd07yu919i+ERGbab3ltsEZn35CSvW93E63uylOtedESWs2VYHJnl/ip71TlZdjucleS62bKrjlQ+f9HDjya5dpK3Z9n8fv2poVgru+a9xRaRNbC6JsD5Sa7e3Te+tOcfjqrqEUku7O7TpmdZB6sDyz6xl44F2aiq/ijJvbMc/X+dLG+wF2333D16QbNXJPmt7n52VT09ydWSPDLJ/bKcummLCLvmvcUWkfXw5Cz7fB82PchOqqrf2fDpEUlOqapvTfLGfOHBmXvtgMRjk/zfq4PO9uL6+PEsW4RukOQ3s1yo69zRidbLI7JcMTNZjgl5QZbjq85O8gNTQ62bqnprkht09159r9sV7y179T/OunlqlhsUPXF6kB128y2fH9g1c6Mty/fiZrsb5/N32d1z62N1k7sXJJ+7/sFvdLcQWenuv97w8buS3LiqrprknLaZe6Pfy7K1aK/aFe8tds0AAGMcAAYAjBEiAMAYIbImqurU6RnWifWxmfWxmfWxmfWxmfWx2bqvDyGyPtb6L8oA62Mz62Mz62Mz62Mz62OztV4fQgQAGLPnz5q5Uh3dx3zudPw5F+aCHJWjp8dYG9bHZtbHZtbHZtbHZtbHZuuyPs7NOWd39zW2Lt/z1xE5JsflG2ptr3wLAIeFF/cz37vdcrtmAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxh0WIVNWTqur503MAAJfPvukBDpEHJqkkqaqXJ3lzdz9gdCIA4FIdFiHS3R+fngEAuPwOixCpqicluXqSs5PcOcmdq+r+q4dP6u73DI0GAFyCwyJENnhgkhsmeVuSX1wt++jcOADAJTmsQqS7P15Vn0nyqe7+8MGeV1WnJjk1SY7JsTs1HgCwxWFx1szl1d2nd/f+7t5/VI6eHgcA9qw9GSIAwHo4HEPkM0mOnB4CALh0h2OIvCfJbavqulV19ao6HH9GADgsHI5v0o/NslXkLVnOmLnO7DgAwMEcFmfNdPd9Nnz8jiS3n5sGALisDsctIgDALiFEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAx+6YHmFZHHJEjvuTY6THWxpmn3XJ6hLVy5Pk1PcJaud7p75keYa1c/LGPT4+wVi4+/9PTI6yXiy+anmBXsEUEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMYddiFTVN1bVa6rqvKr6eFW9tqpuNj0XAPCF9k0PcChV1b4kz0nyJ0lOSXJUklsnuWhyLgBge4dViCQ5IclVkjyvu/91textW59UVacmOTVJjqnjdm46AGCTw2rXTHf/R5InJfnrqnpBVT24qq6zzfNO7+793b3/SnXMjs8JACwOqxBJku7+0STfkOQVSb4zydur6uTZqQCA7Rx2IZIk3f3P3f3o7r5LkpcnuffsRADAdg6rEKmqk6rq16rqDlX11VX1TUlukeQt07MBAF/ocDtY9VNJbpjkL5NcPclHkjwtyaMnhwIAtndYhUh3fyTJ907PAQBcNofVrhkAYHcRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAmH3TA0zr7vRFF02PsTZu8OtnTo+wVq7/Vx+bHmGtvPPZN5geYa0cse/I6RHWSv/bh6ZHWCt98fQEu4MtIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAmF0fIlV1pekZAIAvzo6GSFWdWlUfqaojtyx/elU9d/Xxd1TV66rq01X17qp6xMbYqKr3VNVpVfWnVfWxJE+rqpdW1eO3vOYJVfWpqvreHfnhAIDLbae3iPxlkisn+dYDC6rq+CTfleSpVXVykqcleXySmya5b5LvS/LILa/z4CRvS7I/yS8meUKSH66qozc85x5JzkvyvCvkJwEA/tN2NES6+5wk/yfJKRsWf3eSzyZ5bpKHJfn17n5id/9rd78syc8n+fGqqg1f87fd/ZjuPrO735nkWUkuTvI9G55z3yRP7u4Lt86x2jJzRlWdcWF/+pD+jADAZTdxjMhTk3x3VR27+vyUJP+7uz+d5DZJHlZV5x34k+TpSY5Lcq0Nr3HGxhfs7guSPCVLfKSqbprktkn+ZLsBuvv07t7f3fuPqmMO4Y8GAFwe+wa+5wuybAH5rqp6SZJvSXLy6rEjkvxqll04W310w8ef3ObxP07yxqq6TpYgeXV3v/WQTQ0AHHI7HiLdfUFV/WWWLSFXT/LhJC9fPfz6JDfq7jO/iNf9l6r6hyT3S3LPLLt5AIA1NrFFJFl2z7wkyUlJ/qy7L14tf3iS51fVe5M8I8uWk5sluW13/9xleN0nJPnDJBcm+YtDPjUAcEhNXUfklUn+LclNskRJkqS7/zrJ3ZN8U5LXrv78QpL3XcbX/Yskn0nyjO4+91AODAAceiNbRLq7k1z3II/9TZK/uYSv3fbrVq6S5EtykINUAYD1MrVr5pCqqqOSXC3L9Ub+qbv/fngkAOAy2PWXeF+5Y5IPJblDloNVAYBd4LDYItLdL09Sl/Y8AGC9HC5bRACAXUiIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMGbf9ADjutMXfnZ6irVx0Uc/Oj3CWnnHj99seoS1cubPHjU9wlq5xvNPmB5hrVz15RdOj7BWPvuhD0+PsCvYIgIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjNmVIVJVp1XVmy/lOY+vqpfv0EgAwBdhV4YIAHB4ECIAwJixEKnFQ6rqnVV1QVV9oKoetXrs5lX14qo6v6r+o6qeVFVXvoTXOrKqHltV56z+/HaSI3fshwEAviiTW0QemeSXkjwqyU2TfH+S91fVcUn+Osl5SW6b5HuS3CHJn17Caz0kyf2S/FiS22eJkFOusMkBgENi38Q3rarjk/x0kgd194HAODPJq6vqfkmOS3Kv7j539fxTk7ysqq7f3Wdu85IPSvKY7n7G6vkPTHLyJXz/U5OcmiTH5NhD9FMBAJfX1BaRmyQ5OslLtnnsxkneeCBCVl6V5OLV122y2mVzYpJXH1jW3Rcn+YeDffPuPr2793f3/qNy9Bf3EwAA/2m77WDVnh4AADh0pkLkrUkuSHLXgzx286r60g3L7pBl1rdufXJ3fzzJh5Lc7sCyqqosx5cAAGts5BiR7j63qh6X5FFVdUGSVyS5WpLbJPl/k/xqkidX1S8n+bIkf5TkWQc5PiRJHpfkoVX1jiRvSvKTWXbXfOiK/UkAgP+MkRBZeWiSc7KcOfOVST6S5Mnd/amqOjnJbyd5bZJPJ3lOkgdewmv9RpJrJfnj1edPSfK0LMebAABraixEVgeU/trqz9bH3pTtd9scePy0JKdt+PyzWc7C+elDPScAcMXZbQerAgCHESECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIzZNz3AWrj4oukJWFN9xpunR1gr17vXkdMjrJV3/s7+6RHWyr/f/KTpEdbK9f/0S6ZHWC/v3H6xLSIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwJgdDZGqenlVPX4nvycAsL5sEQEAxuz6EKmqo6ZnAAC+OBMhckRVPbKqzq6qs6rqsVV1RJJU1ZWq6tFV9YGq+lRV/WNVnXzgC6vqLlXVVXW3qnptVX0mycm1+Lmq+teqOr+q3lRV9xz42QCAy2HfwPc8Jcnjktwhya2SPD3J65L8WZInJrlekh9O8oEkd0vyvKr6+u7+5w2v8egkD0lyZpJzk/yvJN+X5P5J3p7k9kmeUFXndPcLtg5QVacmOTVJjsmxV8CPCABcFhMh8pbu/uXVx++oqvsluWtVvTbJPZJct7vft3r88VX1LUl+LMlPbniN07r7b5Kkqo5L8uAk39bdr1w9/u6qum2WMPmCEOnu05OcniQn1FX70P54AMBlNREib9zy+QeTfHmSWyepJG+pqo2PH53kpVu+5owNH98kyTFJXlhVG6PiqCTvOQTzAgBXkIkQuXDL553lWJUjVh9//TbPOX/L55/c8PGB41y+I8n7tjxv6+sAAGtkIkQO5p+ybBG5Vne/7HJ83VuSXJDkq7t765YTAGCNrU2IdPc7quppSZ5UVQ9J8vokV01ylyTv6u5nHeTrzq2qxyZ5bC37dF6R5Pgkt0ty8ep4EABgDa1NiKz8aJKHJXlMkq9M8h9JXpvk0raQ/FKSjyT5mSR/kOQTSd6weh0AYE3taIh09122WXafDR9fmOS01Z/tvv7lWXbfbF3eSX539QcA2CV2/ZVVAYDdS4gAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGP2TQ8A7CIXXzQ9wVq5wU+dMT3CWqlb3mh6hLXyhy99yvQIa+Wkr9p+uS0iAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMCYfdMDTKiqU5OcmiTH5NjhaQBg79qTW0S6+/Tu3t/d+4/K0dPjAMCetSdDBABYD0IEABgjRACAMYdtiFTVA6rqbdNzAAAHd9iGSJKrJ/na6SEAgIM7bEOku0/r7pqeAwA4uMM2RACA9SdEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGNoTURMAAAZoSURBVCNEAIAx+6YHAHaRqukJWGNHnv3x6RHWynX2HT89wq5giwgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMGbXhEhV/UxVvWd6DgDg0Nk1IQIAHH4OSYhU1QlVdZVD8VqX43teo6qO2cnvCQAcWl90iFTVkVV1clU9PcmHk9xytfzKVXV6VZ1VVedW1d9W1f4NX3efqjqvqu5aVW+uqk9W1cuq6qQtr/9zVfXh1XOfnOT4LSPcLcmHV9/rjl/szwEAzLncIVJVN62qxyR5f5K/SPLJJP81ySuqqpK8IMm1k3x7kq9L8ookL62qEze8zNFJHprkvklun+QqSf5ww/f4gST/K8mvJLl1krcnefCWUZ6W5IeTfGmSF1XVmVX1y1uD5iA/w6lVdUZVnXFhLri8qwAAOESquy/9SVVXS3JKknsnuXmSFyZ5SpLndfenNzzvm5M8N8k1uvv8DcvfkOTp3f2YqrpPkicmuVF3v331+ClJ/jTJMd3dVfWqJP/S3ffb8BovTnL97r7uNvOdkOT7ktwryX9J8ndJnpzkGd193iX9bCfUVfsb6q6Xug6AJFXTE6yXcpjdRvuufeKlP2kPecE/PH96hLVy5Ilnvq67929dfln/L/p/kjwuyaeT3LC7v7O7/3JjhKzcJsmxST662qVyXlWdl+RmSa634XkXHIiQlQ8muVKSL1t9fuMkr97y2ls//5zu/kR3/2l3f1OSr09yzSR/kiVOAIA1te8yPu/0JBcm+ZEkb66qZ2fZIvKS7r5ow/OOSPKRLFsltvrEho8/u+WxA5tlvqhfL6rq6Cy7gu6Z5diRf0nyoCTP+WJeDwDYGZfpjb+7P9jdj+jur03yLUnOS/LnST5QVb9RVbdaPfX1WbZGXNzdZ275c9blmOutSW63Zdmmz2txp6r6oywHy/5ukjOT3Ka7b93dj+vucy7H9wQAdtjl3gLR3a/p7p9IcmKWXTY3TPKPVfVfkrw4yd8neU5V/beqOqmqbl9Vv7p6/LJ6XJJ7V9X9quoGVfXQJN+w5Tn3TPI3SU5Ico8kX9XdP9vdb768PxMAMOOy7pr5At19QZJnJnlmVX15kotWB5reLcsZL09I8uVZdtX8fZaDRy/ra/9FVX1NkkdkOebkuUl+M8l9NjztJUmu1d2f+MJXAAB2g8t01szhzFkzcDk4a2YzZ81s4qyZzZw1s9l/9qwZAIBDTogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGP2TQ8A7CLd0xOsl75oeoK18tn3f2B6hLVy8lfcanqENXPmtkttEQEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxuybHmBCVZ2a5NQkOSbHDk8DAHvXntwi0t2nd/f+7t5/VI6eHgcA9qw9GSIAwHoQIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAmOru6RlGVdVHk7x3eo4kV09y9vQQa8T62Mz62Mz62Mz62Mz62Gxd1sdXd/c1ti7c8yGyLqrqjO7ePz3HurA+NrM+NrM+NrM+NrM+Nlv39WHXDAAwRogAAGOEyPo4fXqANWN9bGZ9bGZ9bGZ9bGZ9bLbW68MxIgDAGFtEAIAxQgQAGCNEAIAxQgQAGCNEAIAx/z+OLjgdTpOKswAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# it is terribly cold here\n",
        "# 热力图最后多一个单元，是因为预测时在<end>后添加了空格\n",
        "translate(u'hace mucho frio aqui.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ztrm7LmN8znh",
        "outputId": "203248f2-3787-4346-bc07-a1bec15c97e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "translate(u'esta es mi vida.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tzOkUUhu8zni",
        "outputId": "8e30cc95-d8a3-45d1-faa2-9ae805492346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "Input: <start> ¿ todavia estan en casa ? <end>\n",
            "Predicted translation: are you still at home ? <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "translate(u'¿todavia estan en casa?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qKmmTpBU8zni",
        "outputId": "95f25328-e5c6-483a-84e6-95fd9a7e334b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 1024) (1, 1, 256)\n",
            "(1, 1, 1280)\n",
            "(1, 1, 1024)\n",
            "output变换后\n",
            "(1, 1024)\n",
            "Input: <start> hoy es un buen dia <end>\n",
            "Predicted translation: today is sunny today . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "translate(u'Hoy es un buen día')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "r7K4ci9k8zni"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "seq2seq_attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}