{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.3.4\n",
      "numpy 1.19.5\n",
      "pandas 1.1.5\n",
      "sklearn 0.24.2\n",
      "tensorflow 2.6.2\n",
      "keras.api._v2.keras 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
    "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n",
      "age\n",
      "fare\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                       'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            # categorical_column_with_vocabulary_list可以直接看官网\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "\n",
    "for numeric_column in numeric_columns:\n",
    "    print(numeric_column)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            numeric_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'sex': <tf.Tensor: shape=(), dtype=string, numpy=b'male'>, 'age': <tf.Tensor: shape=(), dtype=float64, numpy=22.0>, 'n_siblings_spouses': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'parch': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'fare': <tf.Tensor: shape=(), dtype=float64, numpy=7.25>, 'class': <tf.Tensor: shape=(), dtype=string, numpy=b'Third'>, 'deck': <tf.Tensor: shape=(), dtype=string, numpy=b'unknown'>, 'embark_town': <tf.Tensor: shape=(), dtype=string, numpy=b'Southampton'>, 'alone': <tf.Tensor: shape=(), dtype=string, numpy=b'n'>}, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(train_df), y_train))  # dict(train_df)\n",
    "\n",
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True,\n",
    "                 batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    # 必须是repeat类型的dataset，进行分批\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'linear_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/wp/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wp/.virtualenvs/tf2/lib/python3.6/site-packages/keras/engine/base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wp/.virtualenvs/tf2/lib/python3.6/site-packages/keras/optimizer_v2/ftrl.py:147: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into linear_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 308.604\n",
      "INFO:tensorflow:loss = 0.63881236, step = 100 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.084\n",
      "INFO:tensorflow:loss = 0.32474536, step = 200 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.852\n",
      "INFO:tensorflow:loss = 0.3958012, step = 300 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.707\n",
      "INFO:tensorflow:loss = 0.514357, step = 400 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.596\n",
      "INFO:tensorflow:loss = 0.3503906, step = 500 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.396\n",
      "INFO:tensorflow:loss = 0.52966213, step = 600 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.43\n",
      "INFO:tensorflow:loss = 0.45952135, step = 700 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.408\n",
      "INFO:tensorflow:loss = 0.43329304, step = 800 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.868\n",
      "INFO:tensorflow:loss = 0.71054685, step = 900 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.58\n",
      "INFO:tensorflow:loss = 0.41074473, step = 1000 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.97\n",
      "INFO:tensorflow:loss = 0.35976493, step = 1100 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.711\n",
      "INFO:tensorflow:loss = 0.2844209, step = 1200 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.293\n",
      "INFO:tensorflow:loss = 0.5646844, step = 1300 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.425\n",
      "INFO:tensorflow:loss = 0.3355224, step = 1400 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.885\n",
      "INFO:tensorflow:loss = 0.5867008, step = 1500 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.809\n",
      "INFO:tensorflow:loss = 0.41145778, step = 1600 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.521\n",
      "INFO:tensorflow:loss = 0.3118695, step = 1700 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.244\n",
      "INFO:tensorflow:loss = 0.51366544, step = 1800 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.897\n",
      "INFO:tensorflow:loss = 0.40734553, step = 1900 (0.211 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1960...\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into linear_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1960...\n",
      "INFO:tensorflow:Loss for final step: 0.4288157.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x7fc2cd475860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output_dir = 'linear_model'\n",
    "if not os.path.exists(linear_output_dir):\n",
    "    os.mkdir(linear_output_dir)\n",
    "\n",
    "# 线性分类器模型\n",
    "linear_estimator = tf.estimator.LinearClassifier(\n",
    "    model_dir = linear_output_dir,\n",
    "    n_classes = 2,\n",
    "    # 之前定义好的feature_columns传入\n",
    "    feature_columns = feature_columns)\n",
    "\n",
    "linear_estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['global_step',\n",
       " 'linear/linear_model/age/weights',\n",
       " 'linear/linear_model/alone_indicator/weights',\n",
       " 'linear/linear_model/bias_weights',\n",
       " 'linear/linear_model/class_indicator/weights',\n",
       " 'linear/linear_model/deck_indicator/weights',\n",
       " 'linear/linear_model/embark_town_indicator/weights',\n",
       " 'linear/linear_model/fare/weights',\n",
       " 'linear/linear_model/n_siblings_spouses_indicator/weights',\n",
       " 'linear/linear_model/parch_indicator/weights',\n",
       " 'linear/linear_model/sex_indicator/weights',\n",
       " 'training/Ftrl/beta',\n",
       " 'training/Ftrl/decay',\n",
       " 'training/Ftrl/l1_regularization_strength',\n",
       " 'training/Ftrl/l2_regularization_strength',\n",
       " 'training/Ftrl/learning_rate',\n",
       " 'training/Ftrl/learning_rate_power',\n",
       " 'training/Ftrl/linear/linear_model/age/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/age/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/alone_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/alone_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/bias_weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/bias_weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/class_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/class_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/deck_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/deck_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/embark_town_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/embark_town_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/fare/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/fare/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/n_siblings_spouses_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/n_siblings_spouses_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/parch_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/parch_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/sex_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/sex_indicator/weights/linear']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5075307],\n",
       "       [-3.0258067],\n",
       "       [-1.3623335],\n",
       "       [ 1.2499554],\n",
       "       [-0.9221774],\n",
       "       [ 2.1498895]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_value('training/Ftrl/linear/linear_model/parch_indicator/weights/linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.6933193],\n",
       "       [3.9346614]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_value('training/Ftrl/linear/linear_model/sex_indicator/weights/accumulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3028\r\n",
      "-rw-rw-r-- 1 wp wp     130 May  4 21:35 checkpoint\r\n",
      "-rw-rw-r-- 1 wp wp 1367038 May  4 21:35 events.out.tfevents.1651671296.ubuntu\r\n",
      "-rw-rw-r-- 1 wp wp  949921 May  4 21:34 graph.pbtxt\r\n",
      "-rw-rw-r-- 1 wp wp     452 May  4 21:34 model.ckpt-0.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 wp wp    1749 May  4 21:34 model.ckpt-0.index\r\n",
      "-rw-rw-r-- 1 wp wp  379665 May  4 21:34 model.ckpt-0.meta\r\n",
      "-rw-rw-r-- 1 wp wp     452 May  4 21:35 model.ckpt-1960.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 wp wp    1749 May  4 21:35 model.ckpt-1960.index\r\n",
      "-rw-rw-r-- 1 wp wp  379665 May  4 21:35 model.ckpt-1960.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-05-04T21:37:14\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from linear_model/model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.71483s\n",
      "INFO:tensorflow:Finished evaluation at 2022-05-04-21:37:15\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.7878788, accuracy_baseline = 0.625, auc = 0.83841443, auc_precision_recall = 0.7826154, average_loss = 0.46759558, global_step = 1960, label/mean = 0.375, loss = 0.45158345, precision = 0.7171717, prediction/mean = 0.38183612, recall = 0.7171717\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: linear_model/model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7878788,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.83841443,\n",
       " 'auc_precision_recall': 0.7826154,\n",
       " 'average_loss': 0.46759558,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.45158345,\n",
       " 'precision': 0.7171717,\n",
       " 'prediction/mean': 0.38183612,\n",
       " 'recall': 0.7171717,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.evaluate(input_fn = lambda : make_dataset(\n",
    "    eval_df, y_eval, epochs = 1, shuffle = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t       tf02_premade_estimators.ipynb\r\n",
      "linear_model\t\t       tf03_premade_estimators-new_feature.ipynb\r\n",
      "tf01_keras_to_estimator.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './dnn_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.3360789, step = 0\n",
      "INFO:tensorflow:global_step/sec: 280.324\n",
      "INFO:tensorflow:loss = 0.64172256, step = 100 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.82\n",
      "INFO:tensorflow:loss = 0.3393709, step = 200 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.439\n",
      "INFO:tensorflow:loss = 0.36703658, step = 300 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.578\n",
      "INFO:tensorflow:loss = 0.5929382, step = 400 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.149\n",
      "INFO:tensorflow:loss = 0.44103703, step = 500 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.137\n",
      "INFO:tensorflow:loss = 0.43974587, step = 600 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.659\n",
      "INFO:tensorflow:loss = 0.44141492, step = 700 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.721\n",
      "INFO:tensorflow:loss = 0.36632812, step = 800 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.369\n",
      "INFO:tensorflow:loss = 0.36072826, step = 900 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.698\n",
      "INFO:tensorflow:loss = 0.37765503, step = 1000 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.933\n",
      "INFO:tensorflow:loss = 0.3638239, step = 1100 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.327\n",
      "INFO:tensorflow:loss = 0.45488185, step = 1200 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.552\n",
      "INFO:tensorflow:loss = 0.5340179, step = 1300 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.927\n",
      "INFO:tensorflow:loss = 0.24324468, step = 1400 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.805\n",
      "INFO:tensorflow:loss = 0.33136418, step = 1500 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.509\n",
      "INFO:tensorflow:loss = 0.3795641, step = 1600 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.185\n",
      "INFO:tensorflow:loss = 0.5005679, step = 1700 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.563\n",
      "INFO:tensorflow:loss = 0.20322126, step = 1800 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.986\n",
      "INFO:tensorflow:loss = 0.19465044, step = 1900 (0.265 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1960...\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1960...\n",
      "INFO:tensorflow:Loss for final step: 0.11402539.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fc3a8f657f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面是使用dnn估计器\n",
    "dnn_output_dir = './dnn_model'\n",
    "if not os.path.exists(dnn_output_dir):\n",
    "    os.mkdir(dnn_output_dir)\n",
    "\n",
    "# 创建dnn估计器\n",
    "dnn_estimator = tf.estimator.DNNClassifier(\n",
    "    model_dir = dnn_output_dir,\n",
    "    n_classes = 2,\n",
    "    feature_columns=feature_columns,\n",
    "    # 因为是dnn，我们定义层，两层，每一层是128\n",
    "    hidden_units = [128, 128,128],\n",
    "    # 激活函数\n",
    "    activation_fn = tf.nn.relu,\n",
    "    # 在Linear也有这个参数，只不过默认的，我们没有设置\n",
    "    optimizer = 'Adam')\n",
    "\n",
    "# 开始训练\n",
    "dnn_estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dnn/hiddenlayer_0/bias',\n",
       " 'dnn/hiddenlayer_0/kernel',\n",
       " 'dnn/hiddenlayer_1/bias',\n",
       " 'dnn/hiddenlayer_1/kernel',\n",
       " 'dnn/hiddenlayer_2/bias',\n",
       " 'dnn/hiddenlayer_2/kernel',\n",
       " 'dnn/logits/bias',\n",
       " 'dnn/logits/kernel',\n",
       " 'global_step',\n",
       " 'training/Adam/beta_1',\n",
       " 'training/Adam/beta_2',\n",
       " 'training/Adam/decay',\n",
       " 'training/Adam/dnn/hiddenlayer_0/bias/m',\n",
       " 'training/Adam/dnn/hiddenlayer_0/bias/v',\n",
       " 'training/Adam/dnn/hiddenlayer_0/kernel/m',\n",
       " 'training/Adam/dnn/hiddenlayer_0/kernel/v',\n",
       " 'training/Adam/dnn/hiddenlayer_1/bias/m',\n",
       " 'training/Adam/dnn/hiddenlayer_1/bias/v',\n",
       " 'training/Adam/dnn/hiddenlayer_1/kernel/m',\n",
       " 'training/Adam/dnn/hiddenlayer_1/kernel/v',\n",
       " 'training/Adam/dnn/hiddenlayer_2/bias/m',\n",
       " 'training/Adam/dnn/hiddenlayer_2/bias/v',\n",
       " 'training/Adam/dnn/hiddenlayer_2/kernel/m',\n",
       " 'training/Adam/dnn/hiddenlayer_2/kernel/v',\n",
       " 'training/Adam/dnn/logits/bias/m',\n",
       " 'training/Adam/dnn/logits/bias/v',\n",
       " 'training/Adam/dnn/logits/kernel/m',\n",
       " 'training/Adam/dnn/logits/kernel/v',\n",
       " 'training/Adam/learning_rate']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 128)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.get_variable_value('training/Adam/dnn/hiddenlayer_0/kernel/m').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-05-04T21:39:50\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.92552s\n",
      "INFO:tensorflow:Finished evaluation at 2022-05-04-21:39:51\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.79545456, accuracy_baseline = 0.625, auc = 0.8480869, auc_precision_recall = 0.8050849, average_loss = 0.5118347, global_step = 1960, label/mean = 0.375, loss = 0.48585257, precision = 0.7227723, prediction/mean = 0.376497, recall = 0.7373737\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: ./dnn_model/model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79545456,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.8480869,\n",
       " 'auc_precision_recall': 0.8050849,\n",
       " 'average_loss': 0.5118347,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.48585257,\n",
       " 'precision': 0.7227723,\n",
       " 'prediction/mean': 0.376497,\n",
       " 'recall': 0.7373737,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评估\n",
    "dnn_estimator.evaluate(input_fn = lambda : make_dataset(\n",
    "    eval_df, y_eval, epochs = 1, shuffle = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
