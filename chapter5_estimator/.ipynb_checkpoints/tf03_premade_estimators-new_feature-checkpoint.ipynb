{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.3.4\n",
      "numpy 1.19.5\n",
      "pandas 1.1.5\n",
      "sklearn 0.24.2\n",
      "tensorflow 2.6.2\n",
      "keras.api._v2.keras 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
    "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n",
      "--------------------------------------------------\n",
      "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
      " NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
      " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
      " IndicatorColumn(categorical_column=CrossedColumn(keys=('age', 'sex'), hash_bucket_size=100, hash_key=None))]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                       'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "\n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            numeric_column, dtype=tf.float32))\n",
    "\n",
    "# 交叉特征的样子\n",
    "# cross feature: age: [1,2,3,4,5], gender:[male, female]\n",
    "# age_x_gender: [(1, male), (2, male), ..., (5, male), ..., (5, female)]\n",
    "\n",
    "# 10000: 100 -> hash(10000 values) % 100   哈希1万个特征模上100，变为100个\n",
    "# 增加一个交叉特征，会拿原有的数据进行组合\n",
    "feature_columns.append(\n",
    "    # 我们要转为indicator_column才能使用\n",
    "    tf.feature_column.indicator_column(\n",
    "        # 添加一组交叉特征\n",
    "        tf.feature_column.crossed_column(\n",
    "            ['age', 'sex'], hash_bucket_size = 100)))\n",
    "\n",
    "print('-' * 50)\n",
    "pprint.pprint(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True,\n",
    "                 batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t      tf01_keras_to_estimator.ipynb\r\n",
      "dnn_model     tf02_premade_estimators.ipynb\r\n",
      "linear_model  tf03_premade_estimators-new_feature.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'linear_model_new_features', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/wp/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wp/.virtualenvs/tf2/lib/python3.6/site-packages/keras/engine/base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wp/.virtualenvs/tf2/lib/python3.6/site-packages/keras/optimizer_v2/ftrl.py:147: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into linear_model_new_features/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 293.598\n",
      "INFO:tensorflow:loss = 0.560557, step = 100 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.951\n",
      "INFO:tensorflow:loss = 0.6005192, step = 200 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.262\n",
      "INFO:tensorflow:loss = 0.5299987, step = 300 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.418\n",
      "INFO:tensorflow:loss = 0.49737588, step = 400 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.265\n",
      "INFO:tensorflow:loss = 0.38568163, step = 500 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.58\n",
      "INFO:tensorflow:loss = 0.27889413, step = 600 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.11\n",
      "INFO:tensorflow:loss = 0.3486027, step = 700 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.82\n",
      "INFO:tensorflow:loss = 0.2950402, step = 800 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.022\n",
      "INFO:tensorflow:loss = 0.38311082, step = 900 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.318\n",
      "INFO:tensorflow:loss = 0.3476876, step = 1000 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.38\n",
      "INFO:tensorflow:loss = 0.3837277, step = 1100 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.1\n",
      "INFO:tensorflow:loss = 0.24050225, step = 1200 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.639\n",
      "INFO:tensorflow:loss = 0.395405, step = 1300 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.737\n",
      "INFO:tensorflow:loss = 0.59919286, step = 1400 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.352\n",
      "INFO:tensorflow:loss = 0.31013638, step = 1500 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.142\n",
      "INFO:tensorflow:loss = 0.27025688, step = 1600 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.131\n",
      "INFO:tensorflow:loss = 0.3093995, step = 1700 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.211\n",
      "INFO:tensorflow:loss = 0.34082234, step = 1800 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.521\n",
      "INFO:tensorflow:loss = 0.49623004, step = 1900 (0.222 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1960...\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into linear_model_new_features/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1960...\n",
      "INFO:tensorflow:Loss for final step: 0.43968508.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x7f86bba05d30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output_dir = 'linear_model_new_features'\n",
    "if not os.path.exists(linear_output_dir):\n",
    "    os.mkdir(linear_output_dir)\n",
    "\n",
    "linear_estimator = tf.estimator.LinearClassifier(\n",
    "    model_dir = linear_output_dir,\n",
    "    n_classes = 2,\n",
    "    feature_columns = feature_columns)\n",
    "\n",
    "linear_estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-05-04T21:44:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from linear_model_new_features/model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.77796s\n",
      "INFO:tensorflow:Finished evaluation at 2022-05-04-21:44:12\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.8030303, accuracy_baseline = 0.625, auc = 0.85292315, auc_precision_recall = 0.7651214, average_loss = 0.46819457, global_step = 1960, label/mean = 0.375, loss = 0.45226574, precision = 0.7196262, prediction/mean = 0.42981753, recall = 0.7777778\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: linear_model_new_features/model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8030303,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.85292315,\n",
       " 'auc_precision_recall': 0.7651214,\n",
       " 'average_loss': 0.46819457,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.45226574,\n",
       " 'precision': 0.7196262,\n",
       " 'prediction/mean': 0.42981753,\n",
       " 'recall': 0.7777778,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.evaluate(input_fn=lambda : make_dataset(\n",
    "    eval_df, y_eval, epochs=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './dnn_model_new_features', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./dnn_model_new_features/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.93141365, step = 0\n",
      "INFO:tensorflow:global_step/sec: 286.048\n",
      "INFO:tensorflow:loss = 0.41441086, step = 100 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.567\n",
      "INFO:tensorflow:loss = 0.44507623, step = 200 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.525\n",
      "INFO:tensorflow:loss = 0.56001055, step = 300 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.676\n",
      "INFO:tensorflow:loss = 0.34921235, step = 400 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.667\n",
      "INFO:tensorflow:loss = 0.46367395, step = 500 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.991\n",
      "INFO:tensorflow:loss = 0.4293049, step = 600 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.227\n",
      "INFO:tensorflow:loss = 0.40679693, step = 700 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.27\n",
      "INFO:tensorflow:loss = 0.23278159, step = 800 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.903\n",
      "INFO:tensorflow:loss = 0.4497347, step = 900 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.628\n",
      "INFO:tensorflow:loss = 0.15546803, step = 1000 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.798\n",
      "INFO:tensorflow:loss = 0.34980416, step = 1100 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.805\n",
      "INFO:tensorflow:loss = 0.23958376, step = 1200 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.604\n",
      "INFO:tensorflow:loss = 0.21783622, step = 1300 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.249\n",
      "INFO:tensorflow:loss = 0.19159836, step = 1400 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.599\n",
      "INFO:tensorflow:loss = 0.19673128, step = 1500 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.655\n",
      "INFO:tensorflow:loss = 0.18548179, step = 1600 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.23\n",
      "INFO:tensorflow:loss = 0.6727025, step = 1700 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.047\n",
      "INFO:tensorflow:loss = 0.054837853, step = 1800 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.022\n",
      "INFO:tensorflow:loss = 0.14628308, step = 1900 (0.235 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1960...\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into ./dnn_model_new_features/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1960...\n",
      "INFO:tensorflow:Loss for final step: 0.049489707.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f86bb0b3978>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_output_dir = './dnn_model_new_features'\n",
    "if not os.path.exists(dnn_output_dir):\n",
    "    os.mkdir(dnn_output_dir)\n",
    "\n",
    "dnn_estimator = tf.estimator.DNNClassifier(\n",
    "    model_dir = dnn_output_dir,\n",
    "    n_classes = 2,\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units = [128, 128],\n",
    "    activation_fn = tf.nn.relu,\n",
    "    optimizer = 'Adam')\n",
    "\n",
    "dnn_estimator.train(input_fn=lambda : make_dataset(\n",
    "    train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-05-04T22:10:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model_new_features/model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.72809s\n",
      "INFO:tensorflow:Finished evaluation at 2022-05-04-22:10:13\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.79924244, accuracy_baseline = 0.625, auc = 0.8365167, auc_precision_recall = 0.7939662, average_loss = 0.68868023, global_step = 1960, label/mean = 0.375, loss = 0.6490266, precision = 0.75, prediction/mean = 0.36296475, recall = 0.6969697\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: ./dnn_model_new_features/model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79924244,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.8365167,\n",
       " 'auc_precision_recall': 0.7939662,\n",
       " 'average_loss': 0.68868023,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.6490266,\n",
       " 'precision': 0.75,\n",
       " 'prediction/mean': 0.36296475,\n",
       " 'recall': 0.6969697,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.evaluate(input_fn = lambda : make_dataset(\n",
    "    eval_df, y_eval, epochs = 1, shuffle = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
